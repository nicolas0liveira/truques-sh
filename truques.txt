r nossa##################
# Meus Truques  # - trobleshooting
#################

######################
# Terminal or sh    #
#####################

# converter arquivo ods to xls
soffice --convert-to xlsx demandas.ods

# Serpro DNS ovpn rede (vpn)(ovpn)(rede)
systemd-resolve --status

# forçar resolução do dominio serpro pela interface ovpn (vpn)(ovpn)(rede)
sudo systemd-resolve --set-domain=serpro --interface=ovpntun0
 
# setar os dns específicos na interface X (vpn)(ovpn)(rede)
sudo systemd-resolve --set-dns=8.8.8.8 --set-dns=8.8.4.4 --interface=enp5s0

# inserir na configuração do ovpn para forçar o dominio serpro (vpn)(ovpn)(rede)
sudo sed '/domains=()/s/()/("serpro true")/' -i /opt/ovpnserpro/ovpnprivsep

# remover interface problematica (trobleshooting) (ovpn, rede):
ip link delete br-6bab82831303 ip link delete br-f3681cd16956

# reiniciar configurações de DNS (vpn)(ovpn)(rede)
systemctl restart systemd-resolved

# Ver rotas (vpn)(ovpn)(rede) ip
ip r

# Ver interfaces (vpn)(ovpn)(rede) ip
ip a

# Apagar interfaces (vpn)(ovpn)(rede) ip
ip link set dev br-6bab82831303 down

# rede interfaces nmcli
nmcli

# Recriar um dev tunel ovpn
sudo /opt/ovpnserpro/openvpn --mktun --dev ovpntun0 --dev-type tun

# Separar um arquivo csv de evidencias kpi
for i in $(sed -n '2,$p' 1.csv | iconv -f ISO-8859-1 |  csvcut -c 1|sort -u);do sed -n "1p;/^$i,/p" 1.csv > $i.csv

# converter codificação codificacao arquivo para UTF8
iconv -f US-ASCII -t utf-8 file.php > file-utf8.php

>listar os codigos de codificacao disponíveis: ISO8859, UTF-8 etc
iconv -l

# copiar/colar clipboard no terminal copy/paste (git)(shell)(bash)
xsel --clipboard < new-clipboard-contents.txt
xsel --clipboard > current-clipboard-contents.txt


# pesquisar dentro dos arquivos por determinado padrão (find) (egrep)(so)
grep -rnw '/path/to/somewhere/' -e 'pattern'
-r or -R is recursive,
-n is line number, and
-w stands for match the whole word.
-l (lower-case L) can be added to just give the file name of matching files.
-e is the pattern used during the search
Along with these, --exclude, --include, --exclude-dir flags could be used for efficient searching:

This will only search through those files which have .c or .h extensions:
grep --include=\*.{c,h} -rnw '/path/to/somewhere/' -e "pattern"
This will exclude searching all the files ending with .o extension:
grep --exclude=\*.o -rnw '/path/to/somewhere/' -e "pattern"
For directories it's possible to exclude one or more directories using the --exclude-dir parameter. For example, this will exclude the dirs dir1/, dir2/ and all of them matching *.dst/:
grep --exclude-dir={dir1,dir2,*.dst} -rnw '/path/to/somewhere/' -e "pattern"


# ver detalhes do pacote linux
apt show <nome pacote>

# analisar rede wifi tool wiriless info workarround
wget -N -t 5 -T 10 https://github.com/UbuntuForums/wireless-info/raw/master/wireless-info && chmod +x wireless-info && ./wireless-info

################################
# Assinatura Digital e Chaves
###############################

# incluir chave gpg (assinatura digital) wget ssh
wget -O- https://www.virtualbox.org/download/oracle_vbox_2016.asc | sudo gpg --dearmor --yes --output /usr/share/keyrings/oracle-virtualbox-2016.gpg

# incluir chave gpg (assinatura digital wget (serpro) ssh
wget -O- https://assinadorserpro.estaleiro.serpro.gov.br/repository/AssinadorSERPROpublic.asc | sudo gpg --dearmor --yes --output /etc/apt/trusted.gpg.d/assinador-serpro.gpg

source.list.d/assinaor-serpro.list
deb [signed-by=/etc/apt/trusted.gpg.d/assinador-serpro.gpg] https://www.assinadorserpro.estaleiro.serpro.gov.br/repository/ universal stable


# ver cadeia de certificado de um servidor (ssh)(showcerts)
echo -n | openssl s_client -showcerts -connect gitcorporativo.serpro:443 2>/dev/null | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p'

######
# GIT
######

# Generate a SSH key pair (private/public) (git) ssh-keygen
ssh-keygen -t rsa -b 4096 -C "your_email@example.com"

# Test the SSH key (git)
ssh -T git@github.com

# define alternative keys for git ssh
~/.ssh/config
Incluir:
Host github.com
 HostName github.com
 IdentityFile ~/.ssh/id_rsa_github

 >chmod 600 ~/.ssh/config


# verificar repositórios remotos existentes (git)
git remote -v

#mudar a url repositorio remoto (git):
git remote set-url origin git@github.com:{ORG_NAME}/{REPO_NAME}.git

# ajustar o último commit (git)
git commit -a ou git commit --amend
#Por padrão o amend fará o ajuste do último commit gerando um novo commit

# (site link) site bacana sobre git https://gitfichas.com/ (git)
https://gitfichas.com/


#######################
# Instalando Conda
####################

# criar e ativar ambiente no conda python
conda create python=3 --yes --name <nome_env>
conda activate <nome_env>


###############
##Python
###############


# Carregando biblioteca python para trabalhar com números (config ambiente python)
import numpy as np
np.set_printoptions(precision=2)

# Carregando biblioteca python para trabalhar com dataframes (config ambiente python)
import pandas as pd
pd.set_option('precision',3)
pd.set_option('max_columns',10)

# Carregando biblioteca python para visualização de dados (config ambiente python)
from matplotlib import pyplot as plt

# Carregando biblioteca python para visualização de dados, baseada em matplotlib (config ambiente python)
import seaborn as sns 

# Carregando biblioteca python para funções de entrada e saída (config ambiente python)
import os

# Carregando biblioteca python para trabalhar com arquivos no GDrive (config ambiente python)
from google.colab import drive

# montando drive no python (config ambiente python)
drive.mount("/content/drive/")

# setando workdir (config ambiente python)
wDirNicolas = "/content/drive/My Drive/00 - Educação/FGV - MBA Business Analytics e Big Data/17 - Aplicações de Estatística Espacial/estudo de caso/Estudo de Caso COVID em SP/Dados/"
os.chdir(wDirNicolas)
print(os.listdir())


# import gzip com dados das cidades (python) (ingestão de dados) (dados) (cvs) (analise exploratoria)
dados = pd.read_csv("https://github.com/wcota/covid19br/blob/master/cases-brazil-cities-time.csv.gz?raw=true", compression='gzip')
dados["date"] = pd.to_datetime(df_cities["date"])
dados.sample(10)

ou

file = "https://raw.githubusercontent.com/wcota/covid19br/master/cases-brazil-states.csv"
dados = pd.read_csv(file, "r", delimiter = ',', encoding="utf8")
print(type(dados))
dados.columns

# convertendo data texto no formato de data (python) (dados) (analise exploratoria)
dados["date"] = pd.to_datetime(df_cities["date"])
dados.sample(10)

# exibindo informações do dataframe (python) (analise exploratoria)
dados.info()

# exibindo informações do dataframe (python) (analise exploratoria)
dados.describe().transpose()

# exibindo informações do dataframe (python) (analise exploratoria)
dados.head()


# verificando missing values (python) (analise exploratoria)
dados.isna().sum()


# verificando proporção (python) (analise exploratoria)
dados.groupby('state').count()

-- obitos por estado
dados.groupby('Municipio')['Obito'].count()


# verificando proporção com seaborn (python) (analise exploratoria)
sns.catplot(data=dados, kind='count', y='state', height=10)


# verificando correlação  (python) (analise exploratoria)
plt.figure(figsize=(12,12))
sns.heatmap(abs(dados.corr()), annot=True)


# criando uma flag com base em um campo (python) (dados) (analise exploratoria)
dados['flagIdoso'] = np.where(dados['Idade'] >= 70, 1, 0)
ou
df['is_adult'] = df.Age.apply(lambda age: age >= 18)


# (link) (python) (matplotlib) (comandos) (graficos)
https://paulovasconcellos.com.br/15-comandos-de-matplotlib-que-talvez-voc%C3%AA-n%C3%A3o-conhe%C3%A7a-17cf88a75119

# (link) (python) (comandos) (graficos de linha)
https://python-graph-gallery.com/122-multiple-lines-chart/


# Dicas ótimas de pandas (link) (python) (comandos) (graficos) (dataframe)
https://paulovasconcellos.com.br/28-comandos-%C3%BAteis-de-pandas-que-talvez-voc%C3%AA-n%C3%A3o-conhe%C3%A7a-6ab64beefa93

# diretiva para medir tempo jupyther notebook (pyhon)
%%timeit

# Funções de agregação com Pandas (resample) (python)

-- Pandas dataframe.resample() function is primarily used for time series data.
-- resample com função de agregação específica da coluna. Isso cria uma nova amostra de um quadro de dados com um índice semelhante a data e hora, de modo que todos os valores em 3 segundos sejam agregados em uma linha. Os valores das colunas são  calculados como média.

df["Magnitude"].resample("3s").apply([np.mean]).plot()


# Ordenar dataframe  (python)
df2 = df.sort_values(['Country Name', 'Ano'])

# selecionar coluna no pandas/dataframe (python)(pandas)(dados)(analise exploratoria)
df1 = df.iloc[0,0:2].copy() # To avoid the case where changing df1 also changes df

selecionar registros de SP e que tem cod ibge>0
df_cities_info.loc[(df_cities_info['ibge'] >0) & (df_cities_info['state'] == 'SP')]

# Tipo dos dados  (python)
df.dtypes

# GroupBy  group by (python)
https://realpython.com/pandas-groupby/


# tratar NA - Para descartar linhas se houver algum valor NaN: (python)(dados)(pandas)(analise exploratoria)
df.dropna(axis = 0)

# tratar NA - Para descartar colunas se houver algum valor NaN: (python)(dados)(pandas)(analise exploratoria)
df.dropna(axis = 1)

# tratar NA - Para descartar colunas nas quais mais de 10% dos valores estão ausentes:(python)(dados)(pandas)(analise exploratoria)
df.dropna(thresh=len(df)*0.9, axis=1)

# tratar NA - Para substituir todos os valores de NaN por um escalar: (python)(dados)(pandas)(analise exploratoria)
df.fillna(value=10)

# tratar NA - Para substituir os valores de NaN pelos valores da linha anterior: (python)(dados)(pandas)(analise exploratoria)
df.fillna(axis=0, method='ffill')

# tratar NA - Para substituir os valores de NaN pelos valores da coluna anterior: (python)(dados)(pandas)(analise exploratoria)
df.fillna(axis=1, method='ffill')

# tratar NA - Você também pode substituir os valores de NaN pelos valores da próxima linha ou coluna: (python)(dados)(pandas)(analise exploratoria)
Replace with the values in the next row
df.fillna(axis=0, method='bfill')

Replace with the values in the next column
df.fillna(axis=1, method='bfill')

# tratar NA - substituição comum é trocar os valores de NaN pela média. (python)(dados)(pandas)(analise exploratoria)
df['Age'].fillna(value=df['Age'].mean(), inplace=True)

#########################################
#### Funções personalizadas no Python
#########################################

# tratar NA - função personalizada: replaceMissingValues. Trata o nulo de acordo com a estratégia selecionada (funcoes)(função)(funcao)(python)

import numpy as np
from sklearn.impute import SimpleImputer
'''
Trata o nulo de acordo com a estratégia selecionada
As estratérias podem ser: mean, median, most_frequent, constant.
No caso de cosntant, preencher fill_value, o default é 0. 
'''
def replaceMissingValues(df, strategy='mean', fill_value=0):
  imputer = SimpleImputer(missing_values = np.nan, strategy = strategy, fill_value=fill_value)
  imputer = imputer.fit(df)
  return pd.DataFrame(imputer.transform(df), columns=df.columns)


# função personalizada: getFreq. Obtem a proporção de determinado atributo (funcoes)(função)(funcao)(python)
'''
Obtem a proporção de determinado atributo
'''
def getFreq(df, campo):
  dist = pd.DataFrame(df[campo].value_counts(normalize = True))\
  .join(pd.DataFrame(df.groupby(campo).count().iloc[:,1]))

  dist.columns=['%','Freq']

  return dist


# função personalizada: standardVariables. Normaliza variaveis (funcoes)(função)(funcao)(python)
'''
Normaliza variaveis
'''
def standardVariables(df):
  from sklearn.preprocessing import StandardScaler
  sc = StandardScaler()
  sc.fit_transform(df)
  return sc.transform(df)

  
  
  
#########################
R
#########################




#######################
#R: Ingestão de dados
#################

# R (r)(dados)(analise exploratoria)(ingestão de dados) baixar arquivo no R, descompactar arquivo
[baixando base ZIP]
download.file(url = "http://www.mdic.gov.br/balanca/bd/comexstat-bd/ncm/EXP_COMPLETA.zip", # url do arquivo para baixar
              destfile = "data/BASE_COMPLETA.zip") # arquivo de destino

[Descompactando]
datazip <- unzip("data/EXP_COMPLETA.zip", exdir = "data")

[Usando]
dados <- readr::read_csv2("data/EXP_COMPLETA.csv")

# R (r)(dados)(analise exploratoria)(ingestão de dados) importar arquivo csv, importar arquivo xlsx, manipulando dataset com sql

[manipulando dataset com sql]
library(sqldf)
sqldf("Select...")

[importando o arquivo csv]
casos <- read_delim("FGV/Caso de Uso - Projeto Final/Caso de uso/20210525_Casos-e-obitos-ESP.csv", 
                    ";", escape_double = FALSE, trim_ws = TRUE)

[importando o arquivo xlsx]
library("writexl")
write_xlsx(vacinacao_obitos_idosos_pib,"obitos&Vacina&PIB.xlsx")

# R (r)(dados)(analise exploratoria)(ingestão de dados) importar consumir dados api sem autenticacao

[manipulando dataset com sql]
library(sqldf)
sqldf("Select...")






#######################
#R: Ingestão de dados com API
#################

# (links) api R dataset ingestão de dados
https://operdata.com.br/blog/trabalhando-com-api-no-r/

[importando dados API sem necessidade de autenticacao]
> Instalando os pacotes
install.packages(c("httr", "jsonlite"))

> Carregando os pacotes
library(httr)
library(jsonlite)

> Separando a estrutura do endpoint 'endereço' que iremos acessar, em variáveis
base_url <- "https://api.covid19api.com"
path <- "country/brazil/status/confirmed"

endpoint <- paste(base_url, path, sep="/")

>  Fazendo uma solitação GET a API, passando o endereço da requisição e o query string,
>  que são parâmetros que segundo a documentação da API esse endpoint pode receber
res_api <- GET(
  url = endpoint, 
  query = list(
    from = "2020-06-20T00:00:00Z",
    to = "2020-07-07T00:00:00Z"
  )
)

> Nesse momento os nossos dados da requisição estão contidos em um Unicode bruto,
> sendo necessário converter seu conteúdo para um vetor de caracteres
content_text <- rawToChar(res_api$content)

> Convertendo a estrutura JSON no formato caratere para um objeto do R
content_json <- fromJSON(content_text, flatten=TRUE)


# R (r)(dados)(analise exploratoria)(ingestão de dados) importar consumir dados api com API KEY chave acesso

[manipulando dataset com sql]
library(sqldf)
sqldf("Select...")

[importando dados API com autenticacao CHAVE API_KEY]
> Instalando os pacotes
install.packages(c("httr", "jsonlite"))

> Carregando os pacotes
library(httr)
library(jsonlite)

> Separando a estrutura do endpoint 'endereço' que iremos acessar, em variáveis
base_url <- "https://api.covid19api.com"
path <- "country/brazil/status/confirmed"

endpoint <- paste(base_url, path, sep="/")


> Atribuindo o token a uma variável de ambiente do R
> 1° opção: Será aberto um arquivo com todas as variáveis de ambiente e você poderá adicionar uma nova
> usethis::edit_r_environ()
>  2° opção: Cria uma variável, sem a necessidade de abrir o arquivo
> Sys.setenv("KEY_API" = "sua_api")

> Obtendo a variável de ambiente e atribuindo a uma nova variável
key_api <- Sys.getenv("KEY_API")

> Fazendo uma solitação GET a API, passando o endereço da requisição e o query string,
> que neste caso, será a chave e que queremos os detalhes
res_api <- GET(
  url = endpoint, 
  query = list(
    apikey= key_api,
    details = "true"
  )
)

> Nesse momento os nossos dados da requisição estão contidos em um Unicode bruto,
> sendo necessário converter seu conteúdo para um vetor de caracteres
content_text <- rawToChar(res_api$content)

> Convertendo a estrutura JSON no formato caratere para um objeto do R
content_json <- fromJSON(content_text, flatten=TRUE)

# R (r)(dados)(analise exploratoria)(ingestão de dados) importar consumir dados api basic auth autenticacao

[manipulando dataset com sql]
library(sqldf)
sqldf("Select...")

[importando dados API com autenticacao BASIC]
> Instalando os pacotes
install.packages(c("httr", "jsonlite"))

> Carregando os pacotes
library(httr)
library(jsonlite)

user <- "usuario_para_acesso_api"
password <- "senha"

endpoint <- "http://api.endereco.com"

req <- GET(
  url = endpoint, 
  authenticate(
    user, 
    password, 
    type = "basic"
  )
)

> Nesse momento os nossos dados da requisição estão contidos em um Unicode bruto,
> sendo necessário converter seu conteúdo para um vetor de caracteres
content_text <- rawToChar(req$content)

> Convertendo a estrutura JSON no formato caratere para um objeto do R
content_json <- fromJSON(content_text, flatten=TRUE)





######################
##R Manipulando datas
######################

# R Manipulando dados datas - transformando a data em tipo date (lubridate)(ingestão de dados) 
> install.packages('lubridate')
library(lubridate)
final$data_inicio <- dmy(final$data_inicio)






###################
R: processamento de texto
###################

# (processamento de texto) (char) substituir charactere, replace, chartr

[substituir characteres]
chartr("áéíó", "aeio", vacinas$Município)






#################################
R: Text Processing with stringr
#################################


# (link) (processamento de texto) (r) (dados) stringr
https://www.mjdenny.com/Text_Processing_In_R.html
https://github.com/rstudio/cheatsheets/blob/master/strings.pdf
https://stringr.tidyverse.org/



# processamento de texto stringr (r) (dados) (analise exploratoria) lowercase, concatenate text, split text, grep

install.packages("stringr", dependencies = TRUE)
library(stringr)

my_string <- "Example STRING, with example numbers (12, 15 and also 10.2)?!"

[lowercase]
lower_string <- tolower(my_string)

[concatenate text]
second_string <- "Wow, two sentences."
my_string <- paste(my_string,second_string,sep = " ")

[split]
my_string_vector <- str_split(my_string, "!")[[1]]

Notice that the splitting character gets deleted, but we are now left with essentially two sentences, each stored as a separate string. Furthermore, note that a list object is returned the str_split() function, so to access the actual vector containing the split strings, we need to use the [[ ]] list operator and get the first entry.

[grep]
grep("\\?",my_string_vector)

Now, let's imagine we are interested in sentences that contain questions marks. We can search for the string in the resulting my_string_vector that contains a "?" by using the grep() command. This command will return the index in the input vector that contains what we are looking for, or nothing if it could not find a match.

[replace]
str_replace_all(my_string, "e","___")

[extract]
str_extract_all(my_string,"[0-9]+")

[cleaning text funcion]
Clean_String <- function(string){
    # Lowercase
    temp <- tolower(string)
    # Remove everything that is not a number or letter (may want to keep more 
    # stuff in your actual analyses). 
    temp <- stringr::str_replace_all(temp,"[^a-zA-Z\\s]", " ")
    # Shrink down to just one white space
    temp <- stringr::str_replace_all(temp,"[\\s]+", " ")
    # Split it
    temp <- stringr::str_split(temp, " ")[[1]]
    # Get rid of trailing "" if necessary
    indexes <- which(temp == "")
    if(length(indexes) > 0){
      temp <- temp[-indexes]
    } 
    return(temp)
}







#############################################
# R Normalizing, correlation and regression
#############################################

# R (link)(r)(dados)(analise exploratoria)(ingestão de dados) correlação com R correlacao
https://rpubs.com/rcleoni/cor_reg


# R (r)(dados)(analise exploratoria)(ingestão de dados) correlação com R correlacao
>install.packages("PerformanceAnalytics")
library(PerformanceAnalytics)
chart.Correlation(dados, histogram=TRUE, pch=19)

>Lib maneira para análise exploratória
library(GGally)
ggpairs(df[,(3:5)], lower = list(continuous = "smooth"))

> 2
library(GGally)
ggpairs(data
        , mapping = NULL
        , columns = 1:ncol(data)
        , title = NULL
        , upper = list(continuous = "cor", combo = "box_no_facet", discrete = "facetbar", na = "na")
        , lower = list(continuous = "points", combo = "facethist", discrete = "facetbar", na = "na")
        , diag = list(continuous = "densityDiag", discrete = "barDiag", na = "naDiag")
        , params = NULL, xlab = NULL, ylab = NULL
        , axisLabels = c("show", "internal", "none")
        , columnLabels = colnames(data[columns])
        , labeller = "label_value"
        , showStrips = NULL
        , legend = NULL, cardinality_threshold = 15
        , legends = stop("deprecated")
)


# R (r)(dados) Normalizing Normalizando normalizar
#Data Normalizing
#df2CorNorm = scale(df2Cor, center = T)


# R (r)(dados)(link) Normalizing Normalizando normalizar padronizar standard
https://rpubs.com/victorpasson/normalizacao#:~:text=Padroniza%C3%A7%C3%A3o%2FNormaliza%C3%A7%C3%A3o%20no%20R&text=Muitas%20vezes%20quando%20falamos%20em,a%20mesma%20escala%20de%20valores.

[Normalização]
> normalizar tem como objetivo colocar as variáveis dentro do intervalo de 0 e 1, caso tenha resultado negativo -1 e 1.

>Normalmente adotamos normalização Distibucional quando queremos obter simetria dos dados, remoção de valores extremos, etc
df2CorNorm = log(df2Cor$totalObitosPos)
hist(df2CorNorm)
hist(df2Cor$totalObitosPos)

[Padronizar]
> padronizar significa transformar todas as variáveis na mesma ordem de grandeza
df2CorNorm = scale(df2Cor, center = T)
?scale


################################
# Configurando Java
###############################

#configurando as variáveis de ambiente (configurando java)(update-alternatives)
cat /etc/profile.d/java.sh :
#>>> variaveis de ambiente >>>
export JAVA_HOME=/usr/lib/jvm/jdk-17
export PATH=$PATH:$JAVA_HOME/bin
#<<< variaveis de ambiente <<<


# atualizando a referencia (update-alternatives) (configurando java) variáveis de ambiente
sudo update-alternatives — install “/usr/bin/java” “java” “$JAVA_HOME/bin/java” 1
sudo update-alternatives — install “/usr/bin/javac” “javac” “$JAVA_HOME/bin/javac” 1
sudo update-alternatives — install “/usr/bin/javaws” “javaws” “$JAVA_HOME/bin/javaws” 1

# setando qual java usar   (update-alternatives) (configurando java) variáveis de ambiente
sudo update-alternatives — set java $JAVA_HOME/bin/java
sudo update-alternatives — set javac $JAVA_HOME/bin/ javac
sudo update-alternatives — set javaws $JAVA_HOME/bin/javaws

# setando qual java usar   (update-alternatives) (configurando java) variáveis de ambiente
sudo update-alternatives --config java

# ver quais os updates instalados  (update-alternatives) (configurando java) variáveis de ambiente
sudo update-alternatives --list java


###################
# JAVA -Spring
####################

#(link) duvida bacana sobre Event - Java > Spring > eventos
https://app.algaworks.com/forum/topicos/83254/registrando-eventos-na-camada-service

#(link) duvida sobre notafiscal Java > Spring > NFe
https://app.algaworks.com/forum/topicos/84432/duvida-nf-e-pagamentos
