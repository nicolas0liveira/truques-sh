##################
# Meus Truques  #
#################

# converter arquivo ods to xls
soffice --convert-to xlsx demandas.ods


# Serpro DNS ovpn rede (vpn)(ovpn)(rede)
systemd-resolve --status

# forçar resolução do dominio serpro pela interface ovpn (vpn)(ovpn)(rede)
sudo systemd-resolve --set-domain=serpro --interface=ovpntun0
 
# setar os dns específicos na interface X (vpn)(ovpn)(rede)
sudo systemd-resolve --set-dns=8.8.8.8 --set-dns=8.8.4.4 --interface=enp5s0

# inserir na configuração do ovpn para forçar o dominio serpro (vpn)(ovpn)(rede)
sudo sed '/domains=()/s/()/("serpro true")/' -i /opt/ovpnserpro/ovpnprivsep

# reiniciar configurações de DNS (vpn)(ovpn)(rede)
systemctl restart systemd-resolved

# Ver rotas (vpn)(ovpn)(rede)
ip r

# Ver interfaces (vpn)(ovpn)(rede)
ip a

# Apagar interfaces (vpn)(ovpn)(rede)
ip link set dev br-6bab82831303 down


# Reiniciar Bash RC

source ~/.bashrc
ou 
. ~/.bashrc

# Recriar um dev tunel OVPN
sudo /opt/ovpnserpro/openvpn --mktun --dev ovpntun0 --dev-type tun


# Separar um arquivo csv de evidencias kpi
for i in $(sed -n '2,$p' 1.csv | iconv -f ISO-8859-1 |  csvcut -c 1|sort -u);do sed -n "1p;/^$i,/p" 1.csv > $i.csv


###############
##Python
###############

# Carregando biblioteca python para trabalhar com números (config ambiente python)
import numpy as np
np.set_printoptions(precision=2)

# Carregando biblioteca python para trabalhar com dataframes (config ambiente python)
import pandas as pd
pd.set_option('precision',3)
pd.set_option('max_columns',10)

# Carregando biblioteca python para visualização de dados (config ambiente python)
from matplotlib import pyplot as plt

# Carregando biblioteca python para visualização de dados, baseada em matplotlib (config ambiente python)
import seaborn as sns 

# Carregando biblioteca python para funções de entrada e saída (config ambiente python)
import os

# Carregando biblioteca python para trabalhar com arquivos no GDrive (config ambiente python)
from google.colab import drive

# montando drive no python (config ambiente python)
drive.mount("/content/drive/")

# setando workdir (config ambiente python)
wDirNicolas = "/content/drive/My Drive/00 - Educação/FGV - MBA Business Analytics e Big Data/17 - Aplicações de Estatística Espacial/estudo de caso/Estudo de Caso COVID em SP/Dados/"
os.chdir(wDirNicolas)
print(os.listdir())


# import gzip com dados das cidades (python) (ingestão de dados) (dados) (cvs) (analise exploratoria)
dados = pd.read_csv("https://github.com/wcota/covid19br/blob/master/cases-brazil-cities-time.csv.gz?raw=true", compression='gzip')
dados["date"] = pd.to_datetime(df_cities["date"])
dados.sample(10)

ou

file = "https://raw.githubusercontent.com/wcota/covid19br/master/cases-brazil-states.csv"
dados = pd.read_csv(file, "r", delimiter = ',', encoding="utf8")
print(type(dados))
dados.columns

# convertendo data texto no formato de data (python) (dados) (analise exploratoria)
dados["date"] = pd.to_datetime(df_cities["date"])
dados.sample(10)

# exibindo informações do dataframe (python) (analise exploratoria)
dados.info()

# exibindo informações do dataframe (python) (analise exploratoria)
dados.describe().transpose()

# exibindo informações do dataframe (python) (analise exploratoria)
dados.head()


# verificando missing values (python) (analise exploratoria)
dados.isna().sum()


# verificando proporção (python) (analise exploratoria)
dados.groupby('state').count()

-- obitos por estado
dados.groupby('Municipio')['Obito'].count()


# verificando proporção com seaborn (python) (analise exploratoria)
sns.catplot(data=dados, kind='count', y='state', height=10)


# verificando correlação  (python) (analise exploratoria)
plt.figure(figsize=(12,12))
sns.heatmap(abs(dados.corr()), annot=True)


# criando uma flag com base em um campo (python) (dados) (analise exploratoria)
dados['flagIdoso'] = np.where(dados['Idade'] >= 70, 1, 0)
ou
df['is_adult'] = df.Age.apply(lambda age: age >= 18)


# (link) (python) (matplotlib) (comandos) (graficos)
https://paulovasconcellos.com.br/15-comandos-de-matplotlib-que-talvez-voc%C3%AA-n%C3%A3o-conhe%C3%A7a-17cf88a75119

# (link) (python) (comandos) (graficos de linha)
https://python-graph-gallery.com/122-multiple-lines-chart/


# Dicas ótimas de pandas (link) (python) (comandos) (graficos) (dataframe)
https://paulovasconcellos.com.br/28-comandos-%C3%BAteis-de-pandas-que-talvez-voc%C3%AA-n%C3%A3o-conhe%C3%A7a-6ab64beefa93

# diretiva para medir tempo jupyther notebook (pyhon)
%%timeit

# Funções de agregação com Pandas (resample) (python)

-- Pandas dataframe.resample() function is primarily used for time series data.
-- resample com função de agregação específica da coluna. Isso cria uma nova amostra de um quadro de dados com um índice semelhante a data e hora, de modo que todos os valores em 3 segundos sejam agregados em uma linha. Os valores das colunas são  calculados como média.

df["Magnitude"].resample("3s").apply([np.mean]).plot()


# Ordenar dataframe  (python)
df2 = df.sort_values(['Country Name', 'Ano'])

# selecionar coluna no pandas/dataframe (python)(pandas)(dados)(analise exploratoria)
df1 = df.iloc[0,0:2].copy() # To avoid the case where changing df1 also changes df

selecionar registros de SP e que tem cod ibge>0
df_cities_info.loc[(df_cities_info['ibge'] >0) & (df_cities_info['state'] == 'SP')]

# Tipo dos dados  (python)
df.dtypes

# GroupBy  group by (python)
https://realpython.com/pandas-groupby/


# tratar NA - Para descartar linhas se houver algum valor NaN: (python)(dados)(pandas)(analise exploratoria)
df.dropna(axis = 0)

# tratar NA - Para descartar colunas se houver algum valor NaN: (python)(dados)(pandas)(analise exploratoria)
df.dropna(axis = 1)

# tratar NA - Para descartar colunas nas quais mais de 10% dos valores estão ausentes:(python)(dados)(pandas)(analise exploratoria)
df.dropna(thresh=len(df)*0.9, axis=1)

# tratar NA - Para substituir todos os valores de NaN por um escalar: (python)(dados)(pandas)(analise exploratoria)
df.fillna(value=10)

# tratar NA - Para substituir os valores de NaN pelos valores da linha anterior: (python)(dados)(pandas)(analise exploratoria)
df.fillna(axis=0, method='ffill')

# tratar NA - Para substituir os valores de NaN pelos valores da coluna anterior: (python)(dados)(pandas)(analise exploratoria)
df.fillna(axis=1, method='ffill')

# tratar NA - Você também pode substituir os valores de NaN pelos valores da próxima linha ou coluna: (python)(dados)(pandas)(analise exploratoria)
Replace with the values in the next row
df.fillna(axis=0, method='bfill')

Replace with the values in the next column
df.fillna(axis=1, method='bfill')

# tratar NA - substituição comum é trocar os valores de NaN pela média. (python)(dados)(pandas)(analise exploratoria)


df['Age'].fillna(value=df['Age'].mean(), inplace=True)

#########################################
#### Funções personalizadas no Python
#########################################

# tratar NA - função personalizada: replaceMissingValues. Trata o nulo de acordo com a estratégia selecionada (funcoes)(função)(funcao)(python)

import numpy as np
from sklearn.impute import SimpleImputer
'''
Trata o nulo de acordo com a estratégia selecionada
As estratérias podem ser: mean, median, most_frequent, constant.
No caso de cosntant, preencher fill_value, o default é 0. 
'''
def replaceMissingValues(df, strategy='mean', fill_value=0):
  imputer = SimpleImputer(missing_values = np.nan, strategy = strategy, fill_value=fill_value)
  imputer = imputer.fit(df)
  return pd.DataFrame(imputer.transform(df), columns=df.columns)


# função personalizada: getFreq. Obtem a proporção de determinado atributo (funcoes)(função)(funcao)(python)
'''
Obtem a proporção de determinado atributo
'''
def getFreq(df, campo):
  dist = pd.DataFrame(df[campo].value_counts(normalize = True))\
  .join(pd.DataFrame(df.groupby(campo).count().iloc[:,1]))

  dist.columns=['%','Freq']

  return dist


# função personalizada: standardVariables. Normaliza variaveis (funcoes)(função)(funcao)(python)
'''
Normaliza variaveis
'''
def standardVariables(df):
  from sklearn.preprocessing import StandardScaler
  sc = StandardScaler()
  sc.fit_transform(df)
  return sc.transform(df)

  
  
  
#########################
R
#########################

# biblioteca para fazer consultas SQL no dataframe R (r)(dados)(analise exploratoria)
library(sqldf)
sqldf("Select...
      ")
